<!DOCTYPE html>
<html lang="en">
	<head>
		<title>three.js webgl - PLY</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link type="text/css" rel="stylesheet" href="main.css">
	</head>
	<body>
		<!-- Create a canvas to be overlaid on top of the three.js canvas -->
		<canvas id="overlay-canvas" style="position: absolute; left: 0; top: 0;"></canvas>
		<canvas id="three-container" style="position: absolute; left: 0; top: 0; "></canvas>
		<button id="button_1" class="button">    </button>
		<button id="button_2" class="button">    </button>
		<button id="button_3" class="button">    </button>
		
		<!-- Import maps polyfill -->
		<!-- Remove this when import maps will be widely supported -->
		<script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>
		<script type="importmap">
			{
				"imports": {
					"three": "../build/three.module.js",
					"three/addons/": "./jsm/"
				}
			}
		</script>
		<script type="module" src="models.js"></script>
		<!-- <script src="interaction.js"></script> -->

		<div id="container" class="flex-container-row">
			<div class="flex-container-column">
				<div class="my_text">Thousands of screens, millions of people are using social media</div>
				<p class="ai_text">
				Algorithmic ethics, also known as computational ethics, is the study of ethical issues that arise from the development and use of algorithms and computational systems. 
				
				This field of ethics is concerned with the ethical implications of the choices made by designers, programmers, and users of algorithms and computational systems, and the potential consequences of these choices on individuals, groups, and society as a whole.
				</p>
				
				<p class="my_text" >We are under the monitoring of supper company</p>
				<p class="ai_text">
				Algorithmic ethics is a relatively new field of study, and it is closely related to the broader field of computer ethics. 
				
				However, whereas computer ethics is concerned with ethical issues related to the use of computers and information technology in general, algorithmic ethics is specifically focused on the ethical issues that arise from the development and use of algorithms.
				</p>
				
			</div>
			
			<div class="flex-container-column">
				<p>
					<br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br>
					<br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br>
					<br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br>
				</p>
				<div class="my_text">Is there something hidden behind the popular hash tag?</div>
				<div class="my_text">Are we missing any voices?</div>
				<div class="ai_text">
				Big data can create inequalities for a number of reasons. One of the main reasons is that the people who have access to large amounts of data and the resources to analyze it are often the ones who are already advantaged in society, such as large corporations and wealthy individuals. 
				<br></br>
				This means that they are able to gain even more advantages by using this data to their advantage, while those without access to the same data and resources may be left behind. 
				<br></br>
				Additionally, the use of big data can also lead to discriminatory practices, such as unfairly targeting certain groups of people based on the data that is collected about them. This can exacerbate existing inequalities and create new ones.
				</div>
			</div>
		</div>

		

		<div id="container2">
			<div class="my_text">Things hidden behind the screen</div>
			<p class="ai_text">
			Bias and discrimination: Many algorithms and computational systems are designed to make decisions or predictions based on data. However, the data used to train these systems can be biased, which can result in unfair or discriminatory outcomes. For example, a machine learning algorithm that is trained on biased data may make decisions that are based on stereotypes or prejudices, rather than objective criteria.
			</p>
			<br></br>
			<p class="my_text" >Where is your Privacy</p>
			Transparency and accountability: Many algorithms and computational systems operate in complex and opaque ways, which can make it difficult for users to understand how they make decisions or predictions. This lack of transparency can make it difficult to hold these systems accountable when they make mistakes or produce undesirable outcomes.
			<br></br>
			Privacy and surveillance: Algorithms and computational systems are often used to collect, process, and analyze large amounts of personal data. This can raise privacy concerns, as individuals may not be aware of how their data is being used, or how it is being protected from unauthorized access or misuse.

			<p>
				<br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br>
				
			</p>
			
			
			<div class="my_text">Automating Desicion making system creates barriers</div>
			<p class="my_text">What is the impact of algorithm?</p>
				<p class="ai_text">
					<br></br>
					Filter bubbles and echo chambers: Recommendation systems can create what are known as "filter bubbles" or "echo chambers," where users are only exposed to content, products, or services that are similar to what they have previously liked or engaged with. This can limit the diversity of information and perspectives that users are exposed to, and can reinforce existing beliefs and prejudices.
					<br></br>
					Privacy concerns: Recommendation systems often require the collection and analysis of large amounts of personal data. This can raise privacy concerns, as users may not be aware of how their data is being used, or how it is being protected from unauthorized access or misuse.
					<br></br>
					Bias and discrimination: Recommendation systems can be biased if they are trained on biased data. This can result in unfair or discriminatory outcomes, such as recommending products or services that are only available to certain groups of people.
				
				</p>
			Autonomy and control: Algorithms and computational systems are increasingly being used to make decisions that affect individuals and groups, such as decisions about credit, employment, or criminal justice. These systems may be able to make decisions faster and more
			</div>
		</div>	
	</body>
</html>
